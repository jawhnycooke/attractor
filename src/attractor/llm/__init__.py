"""Unified LLM Client - Provider-agnostic LLM interface."""

from attractor.llm.errors import (
    AbortError,
    AccessDeniedError,
    AuthenticationError,
    ConfigurationError,
    ContentFilterError,
    ContextLengthError,
    InvalidRequestError,
    InvalidToolCallError,
    NetworkError,
    NoObjectGeneratedError,
    NotFoundError,
    ProviderError,
    QuotaExceededError,
    RateLimitError,
    RequestTimeoutError,
    SDKError,
    ServerError,
    StreamError,
)
from attractor.llm.models import (
    ContentPart,
    ImageContent,
    Message,
    RateLimitInfo,
    Request,
    Response,
    Role,
    StreamEvent,
    StreamEventType,
    TextContent,
    ThinkingContent,
    ToolCallContent,
    ToolDefinition,
    ToolResultContent,
)
from attractor.llm.client import LLMClient

__all__ = [
    "LLMClient",
    # Errors
    "AbortError",
    "AccessDeniedError",
    "AuthenticationError",
    "ConfigurationError",
    "ContentFilterError",
    "ContextLengthError",
    "InvalidRequestError",
    "InvalidToolCallError",
    "NetworkError",
    "NoObjectGeneratedError",
    "NotFoundError",
    "ProviderError",
    "QuotaExceededError",
    "RateLimitError",
    "RequestTimeoutError",
    "SDKError",
    "ServerError",
    "StreamError",
    # Models
    "ContentPart",
    "ImageContent",
    "Message",
    "RateLimitInfo",
    "Request",
    "Response",
    "Role",
    "StreamEvent",
    "StreamEventType",
    "TextContent",
    "ThinkingContent",
    "ToolCallContent",
    "ToolDefinition",
    "ToolResultContent",
]
